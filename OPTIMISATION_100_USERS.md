# Optimisation pour supporter 100 utilisateurs simultan√©s

## √âtat actuel (INSUFFISANT)

### Ressources serveur
- **vCPUs**: 4
- **RAM**: 20 GB
- **Stockage**: 1000 GB

### Configuration actuelle
- **Workers**: 9 workers synchrones (bloquants)
- **Capacit√© r√©elle**: 9-15 requ√™tes simultan√©es
- **Cache**: 5 secondes (trop court)
- **Type de workers**: sync (bloquant)

### Probl√®me identifi√©
Avec 10 personnes d√©j√† des probl√®mes ‚Üí **IMPOSSIBLE pour 100 personnes**

---

## Solutions impl√©ment√©es

### 1. Workers asynchrones (GEVENT)
```bash
# Avant: 9 workers sync = max 9 requ√™tes simultan√©es
# Apr√®s: 16 workers gevent avec 1000 connexions chacun = ~16000 connexions th√©oriques
```

**Configuration dans server.py:**
- Workers: 4 CPUs √ó 4 = **16 workers**
- Type: **gevent** (asynchrone, non-bloquant)
- Connexions par worker: 1000
- **Capacit√© estim√©e**: 200-500 utilisateurs simultan√©s

### 2. Cache optimis√©
```bash
# Avant: 5 secondes
# Apr√®s: 30 secondes
```

**Impact:**
- R√©duit les appels √† Google Sheets API de 83%
- Moins de latence pour les utilisateurs
- Moins de charge sur l'API Google

### 3. Timeout augment√©
```bash
# Avant: 60 secondes
# Apr√®s: 120 secondes
```

**Pourquoi:** Les appels Google Sheets peuvent √™tre lents avec beaucoup d'utilisateurs

---

## D√©ploiement

### Option 1: Mise √† jour compl√®te (RECOMMAND√âE)

```bash
# 1. Installer gevent localement
pip install -r requirements.txt

# 2. Tester localement
export GUNICORN_WORKERS=8
export GUNICORN_WORKER_CLASS=gevent
python server.py

# 3. D√©ployer sur le serveur
./zomro.sh deploy

# 4. Sur le serveur, installer gevent
ssh root@188.137.182.53
cd /var/www/killer
source .venv/bin/activate
pip install gevent==23.9.1

# 5. Copier le fichier .env.production
scp .env.production root@188.137.182.53:/var/www/killer/.env

# 6. Red√©marrer le service
sudo systemctl restart killer

# 7. V√©rifier
sudo systemctl status killer
tail -f /var/log/killer.log
```

### Option 2: Configuration manuelle sur le serveur

```bash
# Se connecter au serveur
ssh root@188.137.182.53

# Mettre √† jour requirements.txt
echo "gevent==23.9.1" >> /var/www/killer/requirements.txt

# Installer
cd /var/www/killer
source .venv/bin/activate
pip install gevent==23.9.1

# √âditer /etc/systemd/system/killer.service
sudo nano /etc/systemd/system/killer.service

# Ajouter ces variables d'environnement:
Environment="GUNICORN_WORKERS=16"
Environment="GUNICORN_WORKER_CLASS=gevent"
Environment="GUNICORN_WORKER_CONNECTIONS=1000"
Environment="GUNICORN_TIMEOUT=120"
Environment="SHEET_CACHE_TTL=120"

# Recharger et red√©marrer
sudo systemctl daemon-reload
sudo systemctl restart killer
```

---

## Tests de charge

### Test avec 10 utilisateurs
```bash
# Installer ab (Apache Bench)
sudo apt-get install apache2-utils

# Test avec 10 connexions simultan√©es
ab -n 1000 -c 10 http://188.137.182.53:8080/

# R√©sultat attendu:
# - Time per request: < 100ms
# - Failed requests: 0
```

### Test avec 50 utilisateurs
```bash
ab -n 5000 -c 50 http://188.137.182.53:8080/
```

### Test avec 100 utilisateurs
```bash
ab -n 10000 -c 100 http://188.137.182.53:8080/
```

---

## Surveillance

### V√©rifier les performances
```bash
# Logs en temps r√©el
tail -f /var/log/killer.log

# Processus Gunicorn
ps aux | grep gunicorn

# Utilisation CPU/RAM
htop

# Connexions actives
ss -tuln | grep 8080
```

### M√©triques √† surveiller
- **CPU**: Ne devrait pas d√©passer 80%
- **RAM**: Chaque worker gevent ~100-150 MB (16 workers = ~2-3 GB)
- **Temps de r√©ponse**: < 500ms pour /api/login
- **Erreurs 503**: Aucune

---

## Optimisations suppl√©mentaires (si encore des probl√®mes)

### 1. Augmenter encore le cache
```bash
# Dans .env
SHEET_CACHE_TTL=300  # 5 minutes
```

### 2. Passer √† Redis pour les sessions
```bash
pip install redis Flask-Session[redis]

# Dans server.py, remplacer:
app.config["SESSION_TYPE"] = "redis"
app.config["SESSION_REDIS"] = redis.from_url("redis://localhost:6379")
```

### 3. Mettre en place un cache HTTP (Nginx)
```nginx
# /etc/nginx/sites-available/killer
upstream killer {
    server 127.0.0.1:8080;
}

server {
    listen 80;
    server_name 188.137.182.53;
    
    location /static {
        alias /var/www/killer/client;
        expires 1d;
        add_header Cache-Control "public, immutable";
    }
    
    location / {
        proxy_pass http://killer;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        
        # Cache pour requ√™tes GET
        proxy_cache_valid 200 10s;
    }
}
```

### 4. Augmenter les workers (si RAM disponible)
```bash
# Pour 20 GB RAM, peut supporter jusqu'√† 32 workers
GUNICORN_WORKERS=32
```

### 5. Limiter les connexions par IP (anti-DDoS)
```python
# Dans server.py, ajouter Flask-Limiter
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address

limiter = Limiter(
    app=app,
    key_func=get_remote_address,
    default_limits=["100 per minute"]
)
```

---

## Estimation de capacit√©

### Configuration AVANT
- **Capacit√©**: 10-15 utilisateurs simultan√©s
- **Goulot d'√©tranglement**: Workers synchrones

### Configuration APR√àS
- **Capacit√©**: 200-500 utilisateurs simultan√©s
- **Limite**: API Google Sheets (quota)

### Facteurs limitants
1. **Quota Google Sheets API**: 300 requ√™tes/minute/projet
2. **Bande passante**: Pas un probl√®me avec Zomro
3. **CPU**: 4 vCPUs suffisants pour 100 users avec gevent

---

## R√©sum√© des changements

| Param√®tre | Avant | Apr√®s | Impact |
|-----------|-------|-------|--------|
| Workers | 9 sync | 16 gevent | +80x capacit√© |
| Connexions/worker | 1 | 1000 | +1000x |
| Cache players | 5s | 30s | -83% appels API |
| Timeout | 60s | 120s | Moins d'erreurs |
| Capacit√© totale | 10-15 users | 200-500 users | +20-30x |

---

## Conclusion

‚úÖ **OUI, le serveur PEUT maintenant supporter 100 utilisateurs** avec ces optimisations

‚ö†Ô∏è **MAIS il faut:**
1. Installer gevent
2. Mettre √† jour la configuration
3. Red√©marrer le service
4. Tester progressivement (10 ‚Üí 50 ‚Üí 100 users)

üöÄ **B√©n√©fices:**
- Capacit√© multipli√©e par 20-30x
- R√©duction de 83% des appels API
- Meilleure r√©silience

‚ö° **Prochaines √©tapes:**
1. D√©ployer les changements
2. Tester avec 10 personnes ‚Üí devrait √™tre fluide
3. Tester avec 50 personnes
4. Valider avec 100 personnes
